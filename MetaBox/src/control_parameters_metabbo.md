***
####Control parameters for DEDDQN
| Component | Parameter | Value | Description |
|---|---|---|---|
| Agent | $statesize$ | 99 | dimension of optimization status |
|  | $naction$ | 4 | the number of candidates learning strategies |
|  | $batchsize$ | 64 | the number of trajectories in a batch |
|  | $\epsilon$ | 0.1 | threshold for epsilon greedy |
|  | $\gamma$ | 0.99 | discount factor |
|  | $T_{target}$ | 1000 | time period for updating target Q net |
|  | $lr$ | $10^{-4}$ | learning rate |
|  | $memorysize$ | $10^5$ | replay memory size |
|  | $warmupsize$ | $10^4$ | threshold for Q net to be updated |
|  | $GD$ | AdamW | gradient decent optimizer |
| Optimizer | $F$ | 0.5 | scale factor |
|  | $CR$ | 1.0 | crossover rate |
|  | $NP$ | 100 | population size |
|  | $L$ | 10 | the number of historical generations used to calculate optimization status |
|  | $W$ | 50 | the number of recorded best individuals generated by each learning strategy |

***
####Control parameters for DEDQN
| Component | Parameter | Value | Description |
|---|---|---|---|
| Agent | $statesize$ | 4 | dimension of optimization status |
|  | $naction$ | 3 | the number of candidates learning strategies |
|  | $batchsize$ | 64 | the number of trajectories in a batch |
|  | $\epsilon$ | 0.1 | threshold for epsilon greedy |
|  | $\gamma$ | 0.8 | discount factor |
|  | $C$ | 1 | time period for updating target Q net |
|  | $lr$ | $10^{-4}$ | learning rate |
|  | $memorysize$ | $10^2$ | replay memory size |
|  | $warmupsize$ | $64$ | threshold for Q net to be updated |
|  | $GD$ | AdamW | gradient decent optimizer |
| Optimizer | $F$ | 0.5 | scale factor |
|  | $CR$ | 0.5 | crossover rate |
|  | $NP$ | 100 | population size |
|  | $rwsteps$ | 100 | number of FEs used in random warking |

***
####Control parameters for LDE
| Component | Parameter | Value | Description |
|---|---|---|---|
| Agent | $T$ | 50 | the trajectory length |
|  | $L$ | 20 | the number of trajectories |
|  | $b$ | 5 | the number of bins |
|  | $\gamma$ | 0.99 | discount factor |
|  | $lr$ | $5^{-3}$ | learning rate |
|  | $GD$ | Adam | gradient decent optimizer |
| Optimizer | $F$ | 0.5 | scale factor |
|  | $CR$ | 0.5 | crossover rate |
|  | $NP$ | 50 | population size |
|  | $p$ | (0.4-1)*FEs/maxFEs + 1 | pbest rate used in current-to-pbest/1 |


***
####Control parameters for RLHPSDE
| Component | Parameter | Value | Description |
|---|---|---|---|
| Agent | $\alpha$ | 0.8 | learning rate |
|  | $\gamma$ | 0.5 | discount factor |
| Optimizer | $F{init}$ | 0.5 | initial scale factor |
|  | $CR{init}$ | 0.5 | initial crossover rate |
|  | $H$ | $problemdim/2$ | memory size of F and CR |
|  | $NP_{max}$ | $18*problemdim$ | max population size |
|  | $NP_{min}$ | 4 | min population size |
|  | $rwsteps$ | 200 | number of FEs used in random warking |
|  | $stepsize$ | 10 | max step length of random warking |
***
####Control parameters for QLPSO
| Component | Parameter | Value | Description |
|---|---|---|---|
| Agent | $\alpha$ | \[1,0.1\] | learning rate |
|  | $\gamma$ | 0.8 | discount factor |
| Optimizer | $NP$ | 30 | population size |
|  | $c1,c2$ | 1.49 | accelerate coefficients |
|  | $w$ | 0.729 | inertia weight |
***
####Control parameters for RLPSO
| Component | Parameter | Value | Description |
|---|---|---|---|
| Agent | $maxsigma$ | 1 | maximum standard deviation normal distribution |
|  | $minsigma$ | 0.01 | minimum standard deviation of normal distribution |
|  | $maxmu$ | 1 | maximum mean value of normal distribution |
|  | $minmu$ | 0 | minimum mean value of normal distribution |
|  | $lr$ | 10^{-6} | learning rate |
| Optimizer | $NP$ | 100 | population size |
|  | $c1,c2$ | 2.05 | accelerate coefficients |
|  | $w$ | \[0.9,0.4\] | inertia weight |
|  | $max_v$ | 0.1(ub-lb) | maximum permitted velocity |
***
####Control parameters for RLEPSO
| Component | Parameter | Value | Description |
|---|---|---|---|
| Agent | $maxsigma$ | 1 | maximum standard deviation of normal distribution |
|  | $minsigma$ | 0.01 | minimum standard deviation of normal distribution |
|  | $maxmu$ | 1 | maximum mean value of normal distribution |
|  | $minmu$ | 0 | minimum mean value of normal distribution |
|  | $lr$ | 10^{-6} | learning rate |
|  | $ntep$ | 10 | the number of steps to run per update |
|  | $Kepochs$ | 3 | update time per update |
|  | $\epsilon$ | 0.2 | clip factor of probability ratio |
|  | $\gamma$ | 0.999 | discount factor |
| Optimizer | $NP$ | 100 | population size |
|  | $c1,c2$ | 2.05 | accelerate coefficients |
|  | $w$ | \[0.9,0.4\] | inertia weight |
|  | $maxv$ | 0.1(ub-lb) | maximum permitted velocity |
